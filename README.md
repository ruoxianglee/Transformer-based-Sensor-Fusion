# Transformer-based-Sensor-Fusion

| - |      Type                                  |
|---------|--------------------------------------------|
|     1.1   | Two-stage                                  |
| 1.2      | Single-stage                               |
| 2.1       | Early fusion, a.k.a, point-level           |
| 2.2       | Intermediate fusion, a.k.a, proposal-level |
| 2.3       | Late fusion, a.k.a, detection-level        |


## Survey
[Apoorv Singh. 2023] Transformer-Based Sensor Fusion for Autonomous Driving: A Survey
<img width="400" alt="截屏2023-06-23 13 53 05" src="https://github.com/ruoxianglee/Transformer-based-Sensor-Fusion/assets/36948139/6f118cfb-d96d-44fd-9856-9d06e91d7c2b">

## Benchmark
[CARLA Leaderboard](https://leaderboard.carla.org/leaderboard/)

[nuScenes Leaderboard](https://paperswithcode.com/sota/3d-object-detection-on-nuscenes)

## Lidar+Camera
[Aditya Prakash. 2021 CVPR] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving

[Kashyap Chitta. 2022 ] TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving ([Code](https://github.com/autonomousvision/transfuser))

Note:
- Proposal-level fusion
- Dataset based on CARLA
<img width="400" alt="截屏2023-06-23 13 55 01" src="https://github.com/ruoxianglee/Transformer-based-Sensor-Fusion/assets/36948139/3d482ac0-8a35-4a78-b333-ae106ccd3e72">

[Xuyang Bai. 2022 CVPR] TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with Transformers ([Code](https://github.com/XuyangBai/TransFusion/))

Note:
- Deep fusion
- Dataset based on nuScenes
<img width="400" alt="截屏2023-06-23 14 11 33" src="https://github.com/ruoxianglee/Transformer-based-Sensor-Fusion/assets/36948139/a7a26693-4dcf-43fd-941f-5aaab41e6baa">

[Hao Shao. 2022 CoRL] InterFuser: Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer ([Code](https://github.com/opendilab/InterFuser))
<img width="400" alt="截屏2023-06-23 13 53 26" src="https://github.com/ruoxianglee/Transformer-based-Sensor-Fusion/assets/36948139/d242abb6-3a5f-42f3-b9af-fd1cd156e1a6">

[Hao Shao. 2023 CVPR] ReasonNet: End-to-End Driving with Temporal and Global Reasoning
<img width="400" alt="截屏2023-06-23 14 20 10" src="https://github.com/ruoxianglee/Transformer-based-Sensor-Fusion/assets/36948139/bda8755a-4ddb-4c0f-8315-c5d2b58d3bb3">


## Other DL-based fusion
### Survey

[Literature summary for e2e AD](https://github.com/opendilab/awesome-end-to-end-autonomous-driving)

[Danni Wu. 2022] Deep learning for LiDAR-only and LIDAR-fusion 3D perception: a survey
<img width="400" alt="截屏2023-06-24 17 17 14" src="https://github.com/ruoxianglee/Transformer-based-Sensor-Fusion/assets/36948139/81c573f7-200b-46af-8635-95336d85216c">
<img width="400" alt="截屏2023-06-24 17 17 44" src="https://github.com/ruoxianglee/Transformer-based-Sensor-Fusion/assets/36948139/3022da24-0617-4900-ac93-19a3ca181896">
